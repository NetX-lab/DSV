rank:1;tp_group_size:1;cp_group_size:4;dp_group_size:1
rank:2;tp_group_size:1;cp_group_size:4;dp_group_size:1
rank:3;tp_group_size:1;cp_group_size:4;dp_group_size:1
Rank 1; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 1; Ranks in its context parallel group: [0, 1, 2, 3]
Rank 2; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 2; Ranks in its context parallel group: [0, 1, 2, 3]
rank:0;tp_group_size:1;cp_group_size:4;dp_group_size:1
Rank 3; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 3; Ranks in its context parallel group: [0, 1, 2, 3]
Rank 0; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 0; Ranks in its context parallel group: [0, 1, 2, 3]
--------------------------------------------------
args:{'dataset': 'dummy', 'data_path': '', 'json_file': '', 'text_encoder': 't5', 'text_encoder_path': 't5-v1_1-xxl', 'text_encoder_dummy': True, 'pretrained_model_path': 'stabilityai/sd-vae-ft-ema', 'results_dir': './videogen_exp_cp_test', 'pretrained': None, 'ddp_mode': 'fsdp', 'save_end_to_end_time_json_path': './end_to_end_time_low_rank.json', 'model': 'T2V_Model', 'num_heads': 16, 'head_dim': 128, 'num_layers': 32, 'test_large_scale': True, 'num_frames': 500, 'fps': 8, 'image_size': 128, 'num_sampling_steps': 250, 'frame_interval': 3, 'fixed_spatial': False, 'attention_bias': False, 'learn_sigma': True, 'extras': 78, 'tp_group_size': 1, 'cp_group_size': 4, 'dp_group_size': 1, 'zero_stage': 3, 'model_file_path': None, 'flow_matching': True, 'use_profile': False, 'profile_steps': None, 'gradient_allreduce_fp32': True, 'data_type': 'torch.bfloat16', 'dtype': 'torch.bfloat16', 'atten_comp_mode': 'flash', 'note': 'cp_4_low_rank', 'save_ceph': True, 'use_image_num': 0, 'learning_rate': 0.0001, 'ckpt_every': 2000, 'clip_max_norm': 1.0, 'start_clip_iter': 0, 'local_batch_size': 1, 'max_train_steps': 1000000, 'global_seed': 3407, 'num_workers': 5, 'log_every': 1, 'lr_warmup_steps': 0, 'resume_from_checkpoint': None, 'resume_exp_dir': None, 'ckpt_name': None, 'create_new_dir_when_resume': False, 'low_rank_loss': None, 'strict_step_recover': None, 'gradient_accumulation_steps': 1, 'num_classes': None, 'atten_sparse_mode': None, 'window_based_dict': None, 'low_rank_dict': {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}, 'full_attn_config': {'recompute': True, 'spatial_topk_ratio': 1, 'full_topk_ratio': 1, 'save_attn_score': False, 'save_attn_score_path': None}, 'low_rank_config': {'inplace_modify_original_qk': None, 'recompute': None, 'mode': None, 'threshold_value': None, 'detach_from_mainbranch': None, 'spatial_topk_ratio': None, 'temporal_topk_ratio': None, 'norm_loss': None, 'norm_loss_ratio': None, 'select_with_low_rank_softmax': None, 'low_rank_stage_0_steps': None, 'low_rank_qk_merged': None}, 'use_compile': False, 'mixed_precision': False, 'enable_xformers_memory_efficient_attention': False, 'gradient_checkpointing': False, 'save_attention_score': False, 'aggregate_attention_score': True, 'learn_low_rank_attention_score': False, 'stop_step': 40}
--------------------------------------------------
Starting rank=0, global_variable.RANK =0 ,local rank=0, seed=3407, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
Starting rank=2, global_variable.RANK =2 ,local rank=2, seed=3409, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
Starting rank=3, global_variable.RANK =3 ,local rank=3, seed=3410, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
Starting rank=1, global_variable.RANK =1 ,local rank=1, seed=3408, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
Using FSDP!!!
Using FSDP!!!
Using FSDP!!!
Using FSDP!!!
Steps per epoch 10000
Stage 0 steps:-1
Steps per epoch 10000
Stage 0 steps:-1
rank 0: Allocated Memory: 2.80 GB
rank 0: Reserved Memory: 2.92 GB
No low rank loss
rank 3: Allocated Memory: 2.80 GB
rank 3: Reserved Memory: 2.92 GB
No low rank loss
Steps per epoch 10000
Stage 0 steps:-1
rank 1: Allocated Memory: 2.80 GB
rank 1: Reserved Memory: 2.92 GB
No low rank loss
Steps per epoch 10000
Stage 0 steps:-1
rank 2: Allocated Memory: 2.80 GB
rank 2: Reserved Memory: 2.92 GB
No low rank loss
rank:0; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:0; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:3; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:1; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:2; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 0:7359.56103515625 msend-to-end time in step 0:7512.1337890625 ms

end-to-end time in step 0:8159.55615234375 msend-to-end time in step 0:8044.41064453125 ms

(step=0000001/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.10
(step=0000001/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.10
(step=0000001/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.10
(step=0000001/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.11
rank:0; step:1; video_prompt:['Rain falling on the window']
rank:0; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:1; video_prompt:['Rain falling on the window']
rank:3; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:1; video_prompt:['Rain falling on the window']
rank:1; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:1; video_prompt:['Rain falling on the window']
rank:2; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 1:825.321533203125 msend-to-end time in step 1:843.9342651367188 msend-to-end time in step 1:820.8179321289062 msend-to-end time in step 1:852.7870483398438 ms



(step=0000002/epoch=0000) Train Loss: 2.0938, Train Steps/Sec: 0.93(step=0000002/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.93(step=0000002/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.93


(step=0000002/epoch=0000) Train Loss: 1.9453, Train Steps/Sec: 0.93
rank:1; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:1; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:3; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:0; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:2; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 2:816.8613891601562 msend-to-end time in step 2:809.7042846679688 msend-to-end time in step 2:808.3510131835938 ms


end-to-end time in step 2:813.99755859375 ms
(step=0000003/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.92(step=0000003/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.92(step=0000003/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.92


(step=0000003/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.92
rank:3; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 3:855.070068359375 msend-to-end time in step 3:826.8182373046875 ms

end-to-end time in step 3:825.5750732421875 ms
end-to-end time in step 3:862.318115234375 ms
(step=0000004/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.90(step=0000004/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.90

(step=0000004/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.90
(step=0000004/epoch=0000) Train Loss: 1.9922, Train Steps/Sec: 0.90
rank:0; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 4:872.1370849609375 ms
end-to-end time in step 4:859.5048828125 ms
end-to-end time in step 4:849.6717529296875 ms
end-to-end time in step 4:832.1055908203125 ms
(step=0000005/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90(step=0000005/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.90

(step=0000005/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.90
(step=0000005/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.90
rank:0; step:5; video_prompt:['A musician playing guitar']
rank:0; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:5; video_prompt:['A musician playing guitar']
rank:3; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:5; video_prompt:['A musician playing guitar']
rank:2; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:5; video_prompt:['A musician playing guitar']
rank:1; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 5:796.2682495117188 msend-to-end time in step 5:799.1929321289062 ms

end-to-end time in step 5:828.9299926757812 ms
end-to-end time in step 5:815.0870971679688 ms
(step=0000006/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.93(step=0000006/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.93(step=0000006/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.93


(step=0000006/epoch=0000) Train Loss: 1.9219, Train Steps/Sec: 0.93
rank:1; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 6:797.0969848632812 ms
end-to-end time in step 6:797.9913330078125 ms
end-to-end time in step 6:812.4544677734375 ms
end-to-end time in step 6:822.4183349609375 ms
(step=0000007/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.90(step=0000007/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.90(step=0000007/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.90


(step=0000007/epoch=0000) Train Loss: 1.9609, Train Steps/Sec: 0.90
rank:3; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 7:850.849853515625 msend-to-end time in step 7:880.1961059570312 msend-to-end time in step 7:882.7595825195312 ms


end-to-end time in step 7:853.1567993164062 ms
(step=0000008/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.88
(step=0000008/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.88
(step=0000008/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.88
(step=0000008/epoch=0000) Train Loss: 2.0625, Train Steps/Sec: 0.87
rank:3; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:3; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:2; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:1; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:0; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 8:864.2262573242188 ms
end-to-end time in step 8:825.2444458007812 ms
end-to-end time in step 8:828.5014038085938 ms
end-to-end time in step 8:826.7691650390625 ms
(step=0000009/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.82
(step=0000009/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.82
(step=0000009/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.82
(step=0000009/epoch=0000) Train Loss: 1.9609, Train Steps/Sec: 0.82
rank:0; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 9:815.4762573242188 msend-to-end time in step 9:829.7975463867188 ms

end-to-end time in step 9:814.3659057617188 ms
end-to-end time in step 9:819.8799438476562 ms
(step=0000010/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.91
(step=0000010/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.91
(step=0000010/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000010/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.91
rank:0; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:0; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:1; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:3; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:2; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 10:848.9590454101562 msend-to-end time in step 10:865.3042602539062 ms

end-to-end time in step 10:844.1802368164062 msend-to-end time in step 10:862.8695068359375 ms

(step=0000011/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89
(step=0000011/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89
(step=0000011/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.89
(step=0000011/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.89
rank:0; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 11:902.5267333984375 ms
end-to-end time in step 11:828.2186889648438 ms
end-to-end time in step 11:825.9447631835938 ms
end-to-end time in step 11:823.5353393554688 ms
(step=0000012/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.90(step=0000012/epoch=0000) Train Loss: 2.0312, Train Steps/Sec: 0.90

(step=0000012/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.90
(step=0000012/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.90
rank:2; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 12:822.52294921875 msend-to-end time in step 12:825.03466796875 ms

end-to-end time in step 12:829.7203369140625 ms
end-to-end time in step 12:823.853515625 ms
(step=0000013/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000013/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.91(step=0000013/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.91

(step=0000013/epoch=0000) Train Loss: 1.9141, Train Steps/Sec: 0.91
rank:2; step:13; video_prompt:['A child riding a bicycle']
rank:2; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:13; video_prompt:['A child riding a bicycle']
rank:3; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:13; video_prompt:['A child riding a bicycle']
rank:0; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:13; video_prompt:['A child riding a bicycle']
rank:1; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 13:912.7562255859375 msend-to-end time in step 13:903.262939453125 msend-to-end time in step 13:919.76171875 msend-to-end time in step 13:899.632080078125 ms



(step=0000014/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.85(step=0000014/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.85(step=0000014/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.85


(step=0000014/epoch=0000) Train Loss: 1.9297, Train Steps/Sec: 0.85
rank:3; step:14; video_prompt:['Children playing in playground in high definition']
rank:3; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:14; video_prompt:['Children playing in playground in high definition']
rank:2; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:14; video_prompt:['Children playing in playground in high definition']
rank:1; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:14; video_prompt:['Children playing in playground in high definition']
rank:0; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 14:855.5314331054688 ms
end-to-end time in step 14:825.687255859375 ms
end-to-end time in step 14:831.237548828125 ms
end-to-end time in step 14:829.0966796875 ms
(step=0000015/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90
(step=0000015/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.90(step=0000015/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90

(step=0000015/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.90
rank:3; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 15:808.8532104492188 ms
end-to-end time in step 15:810.5769653320312 msend-to-end time in step 15:855.7301025390625 ms

end-to-end time in step 15:813.8692626953125 ms
(step=0000016/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.92(step=0000016/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.92

(step=0000016/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.92
(step=0000016/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.92
rank:1; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:1; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:3; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:0; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:2; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 16:818.1884765625 msend-to-end time in step 16:825.9376831054688 ms

end-to-end time in step 16:843.5121459960938 ms
end-to-end time in step 16:817.4934692382812 ms
(step=0000017/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89
(step=0000017/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.89
(step=0000017/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.88
(step=0000017/epoch=0000) Train Loss: 1.8828, Train Steps/Sec: 0.89
rank:3; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 17:811.2211303710938 msend-to-end time in step 17:805.2354125976562 ms

end-to-end time in step 17:798.8919677734375 ms
end-to-end time in step 17:803.975830078125 ms
(step=0000018/epoch=0000) Train Loss: 2.0938, Train Steps/Sec: 0.88
(step=0000018/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.88
(step=0000018/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.88
(step=0000018/epoch=0000) Train Loss: 1.9141, Train Steps/Sec: 0.88
rank:1; step:18; video_prompt:['Children playing in playground in high definition']
rank:1; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:18; video_prompt:['Children playing in playground in high definition']
rank:3; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:18; video_prompt:['Children playing in playground in high definition']
rank:2; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:18; video_prompt:['Children playing in playground in high definition']
rank:0; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 18:793.4577026367188 ms
end-to-end time in step 18:795.0659790039062 msend-to-end time in step 18:807.0022583007812 ms

end-to-end time in step 18:802.0410766601562 ms
(step=0000019/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.93(step=0000019/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.93

(step=0000019/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.93
(step=0000019/epoch=0000) Train Loss: 1.9844, Train Steps/Sec: 0.94
rank:2; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 19:810.1768798828125 msend-to-end time in step 19:804.9655151367188 ms

end-to-end time in step 19:807.1832885742188 ms
end-to-end time in step 19:841.0538940429688 ms
(step=0000020/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.92
(step=0000020/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.92
(step=0000020/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.92
(step=0000020/epoch=0000) Train Loss: 1.9922, Train Steps/Sec: 0.92
rank:2; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 20:823.3970947265625 msend-to-end time in step 20:817.7311401367188 msend-to-end time in step 20:813.2178344726562 ms


end-to-end time in step 20:795.8272705078125 ms
(step=0000021/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.93(step=0000021/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.93(step=0000021/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.93


(step=0000021/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.93
rank:0; step:21; video_prompt:['Rain falling on the window']
rank:0; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:21; video_prompt:['Rain falling on the window']
rank:3; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:21; video_prompt:['Rain falling on the window']
rank:1; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:21; video_prompt:['Rain falling on the window']
rank:2; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 21:844.2235107421875 msend-to-end time in step 21:824.6259765625 ms

end-to-end time in step 21:822.8145751953125 ms
end-to-end time in step 21:821.7067260742188 ms
(step=0000022/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90(step=0000022/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90(step=0000022/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.90


(step=0000022/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.90
rank:3; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:3; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:0; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:1; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:2; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 22:859.2706909179688 msend-to-end time in step 22:858.8675537109375 ms

end-to-end time in step 22:805.0132446289062 msend-to-end time in step 22:805.3023681640625 ms

(step=0000023/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.92(step=0000023/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.92(step=0000023/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.92


(step=0000023/epoch=0000) Train Loss: 1.9844, Train Steps/Sec: 0.92
rank:2; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 23:818.3897094726562 msend-to-end time in step 23:823.9126586914062 msend-to-end time in step 23:817.3659057617188 ms


end-to-end time in step 23:832.297119140625 ms
(step=0000024/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.90
(step=0000024/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.90
(step=0000024/epoch=0000) Train Loss: 1.9531, Train Steps/Sec: 0.91
(step=0000024/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.90
rank:0; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 24:826.4188842773438 msend-to-end time in step 24:831.0755615234375 msend-to-end time in step 24:806.7045288085938 ms


end-to-end time in step 24:827.1289672851562 ms
(step=0000025/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90(step=0000025/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.90(step=0000025/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90


(step=0000025/epoch=0000) Train Loss: 1.9062, Train Steps/Sec: 0.90
rank:0; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 25:851.91748046875 msend-to-end time in step 25:848.67724609375 ms

end-to-end time in step 25:852.6947631835938 msend-to-end time in step 25:861.3828735351562 ms

(step=0000026/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.86(step=0000026/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.86
(step=0000026/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.86

(step=0000026/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.86
rank:3; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 26:806.5735473632812 msend-to-end time in step 26:812.4739379882812 msend-to-end time in step 26:803.0822143554688 msend-to-end time in step 26:804.7950439453125 ms



(step=0000027/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.88(step=0000027/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.88(step=0000027/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.88


(step=0000027/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.88
rank:0; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 27:812.272216796875 msend-to-end time in step 27:810.8527221679688 msend-to-end time in step 27:812.920654296875 msend-to-end time in step 27:823.5305786132812 ms



(step=0000028/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.91(step=0000028/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.91

(step=0000028/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.91
(step=0000028/epoch=0000) Train Loss: 1.8984, Train Steps/Sec: 0.91
rank:0; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 28:823.5505981445312 msend-to-end time in step 28:839.178955078125 msend-to-end time in step 28:807.8304443359375 msend-to-end time in step 28:826.6051025390625 ms



(step=0000029/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.91(step=0000029/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.91

(step=0000029/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.91
(step=0000029/epoch=0000) Train Loss: 1.9453, Train Steps/Sec: 0.91
rank:0; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 29:828.4367065429688 msend-to-end time in step 29:866.3484497070312 ms

end-to-end time in step 29:878.4772338867188 ms
end-to-end time in step 29:852.9210815429688 ms
(step=0000030/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.89(step=0000030/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89

(step=0000030/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.89
(step=0000030/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.89
rank:0; step:30; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:30; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:30; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:30; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:30; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:30; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:30; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:30; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 30:807.4951782226562 ms
end-to-end time in step 30:862.3082885742188 ms
end-to-end time in step 30:799.14599609375 ms
end-to-end time in step 30:870.7093505859375 ms
(step=0000031/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.92(step=0000031/epoch=0000) Train Loss: 2.2812, Train Steps/Sec: 0.92(step=0000031/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.92


(step=0000031/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.92
rank:0; step:31; video_prompt:['Rain falling on the window']
rank:0; step:31; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:31; video_prompt:['Rain falling on the window']
rank:3; step:31; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:31; video_prompt:['Rain falling on the window']
rank:2; step:31; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:31; video_prompt:['Rain falling on the window']
rank:1; step:31; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 31:1065.5343017578125 msend-to-end time in step 31:1101.44775390625 msend-to-end time in step 31:1080.664306640625 msend-to-end time in step 31:1142.5076904296875 ms



(step=0000032/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.74(step=0000032/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.74(step=0000032/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.74


(step=0000032/epoch=0000) Train Loss: 1.9219, Train Steps/Sec: 0.74
rank:3; step:32; video_prompt:['A musician playing guitar']
rank:3; step:32; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:32; video_prompt:['A musician playing guitar']
rank:0; step:32; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:32; video_prompt:['A musician playing guitar']
rank:2; step:32; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:32; video_prompt:['A musician playing guitar']
rank:1; step:32; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 32:806.124755859375 msend-to-end time in step 32:819.8966064453125 msend-to-end time in step 32:854.0056762695312 ms
end-to-end time in step 32:855.744384765625 ms


(step=0000033/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000033/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.91
(step=0000033/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.91
(step=0000033/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.91
rank:0; step:33; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:33; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:33; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:33; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:33; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:33; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:33; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:33; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 33:811.8739624023438 ms
end-to-end time in step 33:828.9777221679688 ms
end-to-end time in step 33:840.6589965820312 msend-to-end time in step 33:809.0408935546875 ms

(step=0000034/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90(step=0000034/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90
(step=0000034/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90

(step=0000034/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.90
rank:3; step:34; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:34; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:34; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:34; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:34; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:34; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:34; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:34; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 34:845.12255859375 msend-to-end time in step 34:810.3783569335938 ms

end-to-end time in step 34:814.732666015625 ms
end-to-end time in step 34:809.930419921875 ms
(step=0000035/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.86
(step=0000035/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.86(step=0000035/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.86

(step=0000035/epoch=0000) Train Loss: 1.8828, Train Steps/Sec: 0.86
rank:2; step:35; video_prompt:['Rain falling on the window']
rank:2; step:35; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:35; video_prompt:['Rain falling on the window']
rank:0; step:35; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:35; video_prompt:['Rain falling on the window']
rank:3; step:35; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:35; video_prompt:['Rain falling on the window']
rank:1; step:35; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 35:820.9176635742188 ms
end-to-end time in step 35:862.7289428710938 msend-to-end time in step 35:855.8896484375 msend-to-end time in step 35:860.5457763671875 ms


(step=0000036/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.89(step=0000036/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.89(step=0000036/epoch=0000) Train Loss: 2.2812, Train Steps/Sec: 0.89


(step=0000036/epoch=0000) Train Loss: 1.9297, Train Steps/Sec: 0.89
rank:3; step:36; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:36; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:36; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:36; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:36; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:36; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:36; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:36; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 36:799.1168212890625 msend-to-end time in step 36:833.0994262695312 msend-to-end time in step 36:838.4859619140625 ms


end-to-end time in step 36:864.1981811523438 ms
(step=0000037/epoch=0000) Train Loss: 2.0938, Train Steps/Sec: 0.91(step=0000037/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.91(step=0000037/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.91


(step=0000037/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.91
rank:0; step:37; video_prompt:['A musician playing guitar']
rank:0; step:37; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:37; video_prompt:['A musician playing guitar']
rank:3; step:37; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:37; video_prompt:['A musician playing guitar']
rank:2; step:37; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:37; video_prompt:['A musician playing guitar']
rank:1; step:37; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 37:877.1025390625 msend-to-end time in step 37:887.9541015625 msend-to-end time in step 37:869.452880859375 msend-to-end time in step 37:866.1986694335938 ms



(step=0000038/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.85
(step=0000038/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.85
(step=0000038/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.85
(step=0000038/epoch=0000) Train Loss: 2.0312, Train Steps/Sec: 0.85
rank:2; step:38; video_prompt:['A cat playing in the garden']
rank:2; step:38; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:38; video_prompt:['A cat playing in the garden']
rank:0; step:38; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:38; video_prompt:['A cat playing in the garden']
rank:3; step:38; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:38; video_prompt:['A cat playing in the garden']
rank:1; step:38; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 38:832.5811157226562 ms
end-to-end time in step 38:864.30322265625 msend-to-end time in step 38:844.229736328125 ms

end-to-end time in step 38:799.1209106445312 ms
(step=0000039/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000039/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000039/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.91
(step=0000039/epoch=0000) Train Loss: 1.9609, Train Steps/Sec: 0.91
rank:3; step:39; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:39; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:39; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:39; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:39; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:39; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:39; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:39; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 39:801.1935424804688 msend-to-end time in step 39:810.41357421875 ms

end-to-end time in step 39:798.8597412109375 ms
end-to-end time in step 39:846.8848876953125 ms
(step=0000040/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.92(step=0000040/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.92(step=0000040/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.92


(step=0000040/epoch=0000) Train Loss: 1.9453, Train Steps/Sec: 0.92
