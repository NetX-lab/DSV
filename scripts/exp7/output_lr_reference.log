rank:0;tp_group_size:1;cp_group_size:4;dp_group_size:1
rank:3;tp_group_size:1;cp_group_size:4;dp_group_size:1
rank:2;tp_group_size:1;cp_group_size:4;dp_group_size:1
rank:1;tp_group_size:1;cp_group_size:4;dp_group_size:1
Rank 0; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 0; Ranks in its context parallel group: [0, 1, 2, 3]
--------------------------------------------------
args:{'dataset': 'dummy', 'data_path': '', 'json_file': '', 'text_encoder': 't5', 'text_encoder_path': 't5-v1_1-xxl', 'text_encoder_dummy': True, 'pretrained_model_path': 'stabilityai/sd-vae-ft-ema', 'results_dir': './videogen_exp_cp_test', 'pretrained': None, 'ddp_mode': 'fsdp', 'save_end_to_end_time_json_path': './end_to_end_time_low_rank.json', 'model': 'T2V_Model', 'num_heads': 16, 'head_dim': 128, 'num_layers': 32, 'test_large_scale': True, 'num_frames': 500, 'fps': 8, 'image_size': 128, 'num_sampling_steps': 250, 'frame_interval': 3, 'fixed_spatial': False, 'attention_bias': False, 'learn_sigma': True, 'extras': 78, 'tp_group_size': 1, 'cp_group_size': 4, 'dp_group_size': 1, 'zero_stage': 3, 'model_file_path': None, 'flow_matching': True, 'use_profile': False, 'profile_steps': None, 'gradient_allreduce_fp32': True, 'data_type': 'torch.bfloat16', 'dtype': 'torch.bfloat16', 'atten_comp_mode': 'flash', 'note': 'cp_4_low_rank', 'save_ceph': True, 'use_image_num': 0, 'learning_rate': 0.0001, 'ckpt_every': 2000, 'clip_max_norm': 1.0, 'start_clip_iter': 0, 'local_batch_size': 1, 'max_train_steps': 1000000, 'global_seed': 3407, 'num_workers': 5, 'log_every': 1, 'lr_warmup_steps': 0, 'resume_from_checkpoint': None, 'resume_exp_dir': None, 'ckpt_name': None, 'create_new_dir_when_resume': False, 'low_rank_loss': None, 'strict_step_recover': None, 'gradient_accumulation_steps': 1, 'num_classes': None, 'atten_sparse_mode': None, 'window_based_dict': None, 'low_rank_dict': {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}, 'full_attn_config': {'recompute': True, 'spatial_topk_ratio': 1, 'full_topk_ratio': 1, 'save_attn_score': False, 'save_attn_score_path': None}, 'low_rank_config': {'inplace_modify_original_qk': None, 'recompute': None, 'mode': None, 'threshold_value': None, 'detach_from_mainbranch': None, 'spatial_topk_ratio': None, 'temporal_topk_ratio': None, 'norm_loss': None, 'norm_loss_ratio': None, 'select_with_low_rank_softmax': None, 'low_rank_stage_0_steps': None, 'low_rank_qk_merged': None}, 'use_compile': False, 'mixed_precision': False, 'enable_xformers_memory_efficient_attention': False, 'gradient_checkpointing': False, 'save_attention_score': False, 'aggregate_attention_score': True, 'learn_low_rank_attention_score': False, 'stop_step': 30}
--------------------------------------------------
Rank 3; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 3; Ranks in its context parallel group: [0, 1, 2, 3]
Rank 1; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 1; Ranks in its context parallel group: [0, 1, 2, 3]
Rank 2; Ranks in its data parallel group: [0, 1, 2, 3]
Rank 2; Ranks in its context parallel group: [0, 1, 2, 3]
Starting rank=0, global_variable.RANK =0 ,local rank=0, seed=3407, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
Starting rank=3, global_variable.RANK =3 ,local rank=3, seed=3410, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
Starting rank=2, global_variable.RANK =2 ,local rank=2, seed=3409, world_size=4.
Starting rank=1, global_variable.RANK =1 ,local rank=1, seed=3408, world_size=4.
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
model config: number_attenion_heads: 16, attention_head_dim: 128, norm_type: ada_norm_single, patch_size: 2, sample_size: 16, in_channels: 4, out_channels: 8, num_layers: 32
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: {'mse_loss_weight': 0.1, 'cosine_loss_weight': 0.9, 'disaggregated': True}
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
window_based_dict: None; low_rank_dict: None
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
feed_forward_chunk_size: None, feed_forward_chunk_dim: 0
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
original temp_pos_embed: (500, 2048)
after cp temp_pos_embed: (125, 2048)
register temp_pos_embed: torch.Size([1, 125, 2048])
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
init dummy sampled sparsity for 32 layers
Using FSDP!!!
Using FSDP!!!
Using FSDP!!!
Using FSDP!!!
Steps per epoch 10000
Stage 0 steps:-1
rank 3: Allocated Memory: 2.80 GB
rank 3: Reserved Memory: 2.92 GB
No low rank loss
Steps per epoch 10000
Stage 0 steps:-1
rank 1: Allocated Memory: 2.80 GB
rank 1: Reserved Memory: 2.92 GB
No low rank loss
Steps per epoch 10000
Stage 0 steps:-1
rank 0: Allocated Memory: 2.80 GB
rank 0: Reserved Memory: 2.92 GB
No low rank loss
rank:3; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:3; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
Steps per epoch 10000
Stage 0 steps:-1
rank 2: Allocated Memory: 2.80 GB
rank 2: Reserved Memory: 2.92 GB
No low rank loss
rank:1; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:1; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:0; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:0; video_prompt:['Beautiful lightning striking in storm']
rank:2; step:0; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 0:7722.42919921875 msend-to-end time in step 0:8278.0341796875 msend-to-end time in step 0:7750.60791015625 msend-to-end time in step 0:7244.560546875 ms



(step=0000001/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.11
(step=0000001/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.10
(step=0000001/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.10
(step=0000001/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.10
rank:2; step:1; video_prompt:['Rain falling on the window']
rank:2; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:1; video_prompt:['Rain falling on the window']
rank:1; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:1; video_prompt:['Rain falling on the window']
rank:3; step:1; video_prompt:['Rain falling on the window']
rank:0; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:1; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 1:821.9393920898438 ms
end-to-end time in step 1:856.8546142578125 ms
end-to-end time in step 1:825.4028930664062 msend-to-end time in step 1:822.7012939453125 ms

(step=0000002/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.93(step=0000002/epoch=0000) Train Loss: 2.0938, Train Steps/Sec: 0.93(step=0000002/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.93


(step=0000002/epoch=0000) Train Loss: 1.9453, Train Steps/Sec: 0.93
rank:3; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:3; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:2; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:1; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:2; video_prompt:['Beautiful a train passing through countryside']
rank:0; step:2; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 2:808.3074340820312 msend-to-end time in step 2:879.3088989257812 ms

end-to-end time in step 2:809.8544921875 ms
end-to-end time in step 2:809.83544921875 ms
(step=0000003/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.91(step=0000003/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.91(step=0000003/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.91


(step=0000003/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.91
rank:3; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:3; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:3; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 3:868.4269409179688 ms
end-to-end time in step 3:835.1376342773438 msend-to-end time in step 3:839.4797973632812 ms

end-to-end time in step 3:835.4351806640625 ms
(step=0000004/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.89(step=0000004/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.89(step=0000004/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.89


(step=0000004/epoch=0000) Train Loss: 1.9922, Train Steps/Sec: 0.89
rank:1; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:4; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:4; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 4:820.0117797851562 msend-to-end time in step 4:834.9061279296875 msend-to-end time in step 4:838.0652465820312 msend-to-end time in step 4:844.0687255859375 ms



(step=0000005/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.88(step=0000005/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.88

(step=0000005/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.88
(step=0000005/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.88
rank:0; step:5; video_prompt:['A musician playing guitar']
rank:0; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:5; video_prompt:['A musician playing guitar']
rank:1; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:5; video_prompt:['A musician playing guitar']
rank:3; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:5; video_prompt:['A musician playing guitar']
rank:2; step:5; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 5:820.163330078125 msend-to-end time in step 5:810.5218505859375 msend-to-end time in step 5:804.2431640625 ms


end-to-end time in step 5:799.3799438476562 ms
(step=0000006/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.90(step=0000006/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.90(step=0000006/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.90


(step=0000006/epoch=0000) Train Loss: 1.9219, Train Steps/Sec: 0.90
rank:0; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:6; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:6; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 6:809.9307861328125 ms
end-to-end time in step 6:800.286376953125 msend-to-end time in step 6:816.714599609375 ms

end-to-end time in step 6:839.1967163085938 ms
(step=0000007/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.93
(step=0000007/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.93
(step=0000007/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.92
(step=0000007/epoch=0000) Train Loss: 1.9609, Train Steps/Sec: 0.93
rank:0; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:7; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:7; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 7:823.3832397460938 msend-to-end time in step 7:823.0919799804688 ms

end-to-end time in step 7:826.174072265625 ms
end-to-end time in step 7:852.4825439453125 ms
(step=0000008/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.90(step=0000008/epoch=0000) Train Loss: 2.0625, Train Steps/Sec: 0.90(step=0000008/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.90


(step=0000008/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.90
rank:1; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:1; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:0; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:2; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:8; video_prompt:['Flowers blooming in spring in high definition']
rank:3; step:8; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 8:856.05419921875 msend-to-end time in step 8:828.2100219726562 ms

end-to-end time in step 8:856.1116943359375 msend-to-end time in step 8:853.1070556640625 ms

(step=0000009/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.89(step=0000009/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.89

(step=0000009/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.89
(step=0000009/epoch=0000) Train Loss: 1.9609, Train Steps/Sec: 0.89
rank:2; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:9; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:9; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 9:822.7280883789062 ms
end-to-end time in step 9:856.9042358398438 msend-to-end time in step 9:858.0433959960938 ms

end-to-end time in step 9:886.4799194335938 ms
(step=0000010/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90(step=0000010/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90

(step=0000010/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90
(step=0000010/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.90
rank:0; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:0; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:10; video_prompt:['A chef cooking in the kitchen in high definition']
rank:1; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:10; video_prompt:['A chef cooking in the kitchen in high definition']rank:2; step:10; video_prompt:['A chef cooking in the kitchen in high definition']

rank:3; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:10; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 10:819.6884765625 msend-to-end time in step 10:830.9177856445312 msend-to-end time in step 10:820.2605590820312 msend-to-end time in step 10:881.666015625 ms



(step=0000011/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90(step=0000011/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.90(step=0000011/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90


(step=0000011/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.90
rank:0; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:11; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:11; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 11:820.802734375 msend-to-end time in step 11:856.4898071289062 ms

end-to-end time in step 11:846.0747680664062 ms
end-to-end time in step 11:844.2572631835938 ms
(step=0000012/epoch=0000) Train Loss: 2.0312, Train Steps/Sec: 0.89(step=0000012/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.89

(step=0000012/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.89
(step=0000012/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.89
rank:1; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:12; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:12; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 12:855.6663208007812 ms
end-to-end time in step 12:890.147705078125 msend-to-end time in step 12:839.92529296875 msend-to-end time in step 12:822.0931396484375 ms


(step=0000013/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.89(step=0000013/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89

(step=0000013/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.89
(step=0000013/epoch=0000) Train Loss: 1.9141, Train Steps/Sec: 0.89
rank:0; step:13; video_prompt:['A child riding a bicycle']
rank:0; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:13; video_prompt:['A child riding a bicycle']
rank:2; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:13; video_prompt:['A child riding a bicycle']
rank:1; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:13; video_prompt:['A child riding a bicycle']
rank:3; step:13; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 13:860.1446533203125 msend-to-end time in step 13:864.325927734375 ms

end-to-end time in step 13:824.7584838867188 ms
end-to-end time in step 13:828.058837890625 ms
(step=0000014/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.87(step=0000014/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.87

(step=0000014/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.87
(step=0000014/epoch=0000) Train Loss: 1.9297, Train Steps/Sec: 0.87
rank:1; step:14; video_prompt:['Children playing in playground in high definition']
rank:1; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:14; video_prompt:['Children playing in playground in high definition']
rank:0; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:14; video_prompt:['Children playing in playground in high definition']
rank:2; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:14; video_prompt:['Children playing in playground in high definition']
rank:3; step:14; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 14:826.1580200195312 msend-to-end time in step 14:800.4407958984375 ms

end-to-end time in step 14:798.2315673828125 ms
end-to-end time in step 14:811.6917114257812 ms
(step=0000015/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.90(step=0000015/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90(step=0000015/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90


(step=0000015/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.90
rank:0; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:0; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:1; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:2; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:15; video_prompt:['Birds flying over a lake in slow motion']
rank:3; step:15; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 15:827.6143188476562 ms
end-to-end time in step 15:827.2819213867188 ms
end-to-end time in step 15:831.173583984375 ms
end-to-end time in step 15:882.7769775390625 ms
(step=0000016/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.89(step=0000016/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.89

(step=0000016/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.89
(step=0000016/epoch=0000) Train Loss: 1.9766, Train Steps/Sec: 0.90
rank:0; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:0; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:2; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:1; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:16; video_prompt:['Waves crashing on the beach at sunset']
rank:3; step:16; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 16:840.3502807617188 msend-to-end time in step 16:822.758056640625 msend-to-end time in step 16:839.5774536132812 msend-to-end time in step 16:845.223876953125 ms



(step=0000017/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90(step=0000017/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90(step=0000017/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.90


(step=0000017/epoch=0000) Train Loss: 1.8828, Train Steps/Sec: 0.90
rank:1; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:17; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:17; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 17:826.9417724609375 ms
end-to-end time in step 17:860.818603515625 ms
end-to-end time in step 17:848.6544189453125 msend-to-end time in step 17:883.31689453125 ms

(step=0000018/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.89(step=0000018/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.89(step=0000018/epoch=0000) Train Loss: 2.0938, Train Steps/Sec: 0.89


(step=0000018/epoch=0000) Train Loss: 1.9141, Train Steps/Sec: 0.89
rank:0; step:18; video_prompt:['Children playing in playground in high definition']
rank:0; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:18; video_prompt:['Children playing in playground in high definition']
rank:2; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:18; video_prompt:['Children playing in playground in high definition']
rank:1; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:18; video_prompt:['Children playing in playground in high definition']
rank:3; step:18; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 18:836.15966796875 msend-to-end time in step 18:833.41796875 msend-to-end time in step 18:803.3381958007812 ms


end-to-end time in step 18:857.7067260742188 ms
(step=0000019/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.87(step=0000019/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.87

(step=0000019/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.87
(step=0000019/epoch=0000) Train Loss: 1.9844, Train Steps/Sec: 0.87
rank:0; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:19; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:19; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 19:849.15185546875 ms
end-to-end time in step 19:832.0857543945312 ms
end-to-end time in step 19:860.6133422851562 ms
end-to-end time in step 19:809.1881103515625 ms
(step=0000020/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.88(step=0000020/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.88

(step=0000020/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.88
(step=0000020/epoch=0000) Train Loss: 1.9922, Train Steps/Sec: 0.88
rank:2; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:20; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:20; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 20:878.2310791015625 msend-to-end time in step 20:878.1459350585938 msend-to-end time in step 20:849.3600463867188 ms


end-to-end time in step 20:866.806640625 ms
(step=0000021/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.87
(step=0000021/epoch=0000) Train Loss: 2.2656, Train Steps/Sec: 0.87(step=0000021/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.87

(step=0000021/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.87
rank:0; step:21; video_prompt:['Rain falling on the window']
rank:0; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:21; video_prompt:['Rain falling on the window']
rank:1; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:21; video_prompt:['Rain falling on the window']
rank:2; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:21; video_prompt:['Rain falling on the window']
rank:3; step:21; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 21:855.2623291015625 ms
end-to-end time in step 21:802.1764526367188 msend-to-end time in step 21:850.960693359375 ms

end-to-end time in step 21:819.4930419921875 ms
(step=0000022/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.90
(step=0000022/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.90(step=0000022/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90

(step=0000022/epoch=0000) Train Loss: 2.0000, Train Steps/Sec: 0.90
rank:0; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:0; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:2; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:3; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:22; video_prompt:['Beautiful lightning striking in storm']
rank:1; step:22; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 22:892.2837524414062 msend-to-end time in step 22:833.1838989257812 msend-to-end time in step 22:832.8313598632812 ms


end-to-end time in step 22:865.0032958984375 ms
(step=0000023/epoch=0000) Train Loss: 2.2344, Train Steps/Sec: 0.86(step=0000023/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.86(step=0000023/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.86


(step=0000023/epoch=0000) Train Loss: 1.9844, Train Steps/Sec: 0.86
rank:0; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:0; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:1; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:3; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:23; video_prompt:['A dancer performing on stage in slow motion']
rank:2; step:23; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 23:801.0693969726562 msend-to-end time in step 23:799.6351318359375 msend-to-end time in step 23:817.4603881835938 msend-to-end time in step 23:805.4610595703125 ms



(step=0000024/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.91
(step=0000024/epoch=0000) Train Loss: 2.2969, Train Steps/Sec: 0.91(step=0000024/epoch=0000) Train Loss: 2.1719, Train Steps/Sec: 0.91

(step=0000024/epoch=0000) Train Loss: 1.9531, Train Steps/Sec: 0.91
rank:0; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:24; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:24; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 24:847.2385864257812 ms
end-to-end time in step 24:846.3002319335938 ms
end-to-end time in step 24:821.8421020507812 ms
end-to-end time in step 24:837.9888305664062 ms
(step=0000025/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.89(step=0000025/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.89

(step=0000025/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.89
(step=0000025/epoch=0000) Train Loss: 1.9062, Train Steps/Sec: 0.89
rank:0; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:0; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:2; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:3; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:25; video_prompt:['Fireflies glowing at night in slow motion']
rank:1; step:25; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 25:798.3178100585938 ms
end-to-end time in step 25:798.7678833007812 ms
end-to-end time in step 25:798.9769287109375 ms
end-to-end time in step 25:817.4236450195312 ms
(step=0000026/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.91
(step=0000026/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91
(step=0000026/epoch=0000) Train Loss: 2.2031, Train Steps/Sec: 0.91
(step=0000026/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.91
rank:0; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:26; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:26; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 26:822.5674438476562 msend-to-end time in step 26:825.150146484375 ms

end-to-end time in step 26:878.1029052734375 ms
end-to-end time in step 26:829.7410278320312 ms
(step=0000027/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.90(step=0000027/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.90

(step=0000027/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90
(step=0000027/epoch=0000) Train Loss: 1.9688, Train Steps/Sec: 0.90
rank:0; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:0; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:1; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:1; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:2; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:27; video_prompt:['Beautiful sunset over the ocean in slow motion']
rank:3; step:27; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 27:865.052978515625 ms
end-to-end time in step 27:806.5297241210938 msend-to-end time in step 27:804.3602905273438 msend-to-end time in step 27:808.9320678710938 ms


(step=0000028/epoch=0000) Train Loss: 2.1250, Train Steps/Sec: 0.90
(step=0000028/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.90
(step=0000028/epoch=0000) Train Loss: 2.1562, Train Steps/Sec: 0.90
(step=0000028/epoch=0000) Train Loss: 1.8984, Train Steps/Sec: 0.90
rank:1; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:1; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:3; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:2; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:28; video_prompt:['Beautiful clouds moving across the sky']
rank:0; step:28; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 28:993.7422485351562 msend-to-end time in step 28:993.3544311523438 ms

end-to-end time in step 28:992.6880493164062 ms
end-to-end time in step 28:999.6489868164062 ms
(step=0000029/epoch=0000) Train Loss: 2.2188, Train Steps/Sec: 0.73(step=0000029/epoch=0000) Train Loss: 2.0781, Train Steps/Sec: 0.73(step=0000029/epoch=0000) Train Loss: 2.1094, Train Steps/Sec: 0.73


(step=0000029/epoch=0000) Train Loss: 1.9453, Train Steps/Sec: 0.73
rank:1; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:1; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:0; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:0; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:3; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:3; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
rank:2; step:29; video_prompt:['Traffic flowing on a highway at sunset']
rank:2; step:29; input video shape for this rank after split:torch.Size([1, 125, 3, 128, 128]); text_encoder_hidden_states shape:torch.Size([1, 120, 4096]); encoder_attention_mask shape:torch.Size([1, 120])
end-to-end time in step 29:801.71728515625 ms
end-to-end time in step 29:803.07763671875 ms
end-to-end time in step 29:801.150634765625 msend-to-end time in step 29:833.2293701171875 ms

(step=0000030/epoch=0000) Train Loss: 2.1406, Train Steps/Sec: 0.91(step=0000030/epoch=0000) Train Loss: 2.2500, Train Steps/Sec: 0.91(step=0000030/epoch=0000) Train Loss: 2.1875, Train Steps/Sec: 0.91


(step=0000030/epoch=0000) Train Loss: 2.0156, Train Steps/Sec: 0.91
